{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "32852243"
   },
   "source": [
    "# Project members\n",
    "\n",
    "**Sali Raffaele**:\n",
    "- ðŸ“§ [raffaele.sali@studio.unibo.it](mailto:raffaele.sali@studio.unibo.it)\n",
    "- Student Number: `0001167817`\n",
    "\n",
    "**Zanotti NiccolÃ²**:\n",
    "- ðŸ“§ [niccolo.zanotti@studio.unibo.it](mailto:niccolo.zanotti@studio.unibo.it)\n",
    "- Student Number: `0001121646`\n",
    "\n",
    "**Zocco Ramazzo Marco**:\n",
    "- ðŸ“§ [marco.zoccoramazzo@studio.unibo.it](mailto:marco.zoccoramazzo@studio.unibo.it)\n",
    "- Student Number: `0001198289`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "d41535fd"
   },
   "source": [
    "# Assignment Module 2: Pet Classification\n",
    "\n",
    "The goal of this assignment is to implement a neural network that classifies images of 37 breeds of cats and dogs from the [Oxford-IIIT-Pet dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/). The assignment is divided into two parts: first, you will be asked to implement from scratch your own neural network for image classification; then, you will fine-tune a pretrained network provided by PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Setup and dependencies installation\n",
    "\n",
    "In the following, we will assume that you have \n",
    "- created a local python virtual environment - either with python [venv](https://docs.python.org/3/library/venv.html) module or via [uv](https://github.com/astral-sh/uv) (preferred) - with the `ipykernel` or `jupyter` packages pre-installed to start the jupyter kernel;\n",
    "- have `git` installed on your machine;\n",
    "- have a working internet connection\n",
    "\n",
    "We will now download the `pyproject.toml` file specifying the project dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def get_project_root() -> Path:\n",
    "    \"\"\"Return the root directory of the project.\"\"\"\n",
    "    start_dir = Path.cwd()\n",
    "\n",
    "    markers = [\"assignment2.ipynb\"]\n",
    "\n",
    "    for path in [start_dir, *list(start_dir.parents)]:\n",
    "        for marker in markers:\n",
    "            if (path / marker).exists():\n",
    "                return path\n",
    "\n",
    "    return start_dir\n",
    "\n",
    "\n",
    "PROJECT_ROOT: Path = get_project_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "PROJECT_REPO: str = \"niccolozanotti/ipcv-assignments\"\n",
    "COMMIT_HASH: str = \"9f1f600af59401673e2e816b12d1ae740dc4386b\"\n",
    "\n",
    "pyproject_url = (\n",
    "    f\"https://raw.githubusercontent.com/{PROJECT_REPO}/{COMMIT_HASH}/pyproject.toml\"\n",
    ")\n",
    "lockfile_url = f\"https://raw.githubusercontent.com/{PROJECT_REPO}/{COMMIT_HASH}/uv.lock\"\n",
    "\n",
    "urllib.request.urlretrieve(pyproject_url, PROJECT_ROOT / \"pyproject.toml\")\n",
    "urllib.request.urlretrieve(lockfile_url, PROJECT_ROOT / \"uv.lock\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "If using [uv](https://github.com/astral-sh/uv) (recommended) you can now install the dependencies to a local virtual environment at `.venv` simply via\n",
    "```sh\n",
    "uv sync --extra assignment2\n",
    "```\n",
    "\n",
    "If not, the same can be achieved with the usual python [venv](https://docs.python.org/3/library/venv.html):\n",
    "```sh\n",
    "python3 -m venv .venv\n",
    "source .venv/bin/activate\n",
    "(.venv) pip install \".[assignment2]\" \n",
    "```\n",
    "\n",
    "Make sure to do the above and *restart the kernel* if necessary before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import shutil\n",
    "import subprocess\n",
    "from contextlib import nullcontext  # Allows conditional 'with' statements\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from graphviz import Source as draw_diagram\n",
    "from PIL import Image\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "b1476550"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "The following cells contain the code to download and access the dataset you will be using in this assignment. Note that, although this dataset features each and every image from [Oxford-IIIT-Pet](https://www.robots.ox.ac.uk/~vgg/data/pets/), it uses a different train-val-test split than the original authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91101a0d",
    "outputId": "a9db6786-a66e-49d3-f158-d4c6e28e8faa"
   },
   "outputs": [],
   "source": [
    "BRANCH_NAME: str = \"dataset/assignment2\"\n",
    "REPO_URL: str = f\"https://github.com/{PROJECT_REPO}.git\"\n",
    "\n",
    "temp_dir: Path = PROJECT_ROOT / \"temp_repo\"\n",
    "dataset_path: Path = PROJECT_ROOT / \"dataset\"\n",
    "\n",
    "if dataset_path.exists():\n",
    "    print(f\"'{dataset_path.name}' folder already exists locally. Skipping download.\")\n",
    "else:\n",
    "    try:\n",
    "        print(\n",
    "            f\"Downloading dataset at {PROJECT_REPO}/{BRANCH_NAME} via git sparse checkout...\"\n",
    "        )\n",
    "\n",
    "        # Clone the repo tree\n",
    "        clone_cmd = [\n",
    "            \"git\",\n",
    "            \"clone\",\n",
    "            \"--filter=blob:none\",\n",
    "            \"--sparse\",\n",
    "            \"--depth\",\n",
    "            \"1\",\n",
    "            \"--branch\",\n",
    "            BRANCH_NAME,\n",
    "            REPO_URL,\n",
    "            str(temp_dir),\n",
    "        ]\n",
    "        subprocess.run(clone_cmd, check=True, capture_output=True, text=True)\n",
    "\n",
    "        # Fetch the contents of the 'dataset' folder\n",
    "        sparse_cmd = [\"git\", \"-C\", str(temp_dir), \"sparse-checkout\", \"set\", \"dataset\"]\n",
    "        subprocess.run(sparse_cmd, check=True, capture_output=True, text=True)\n",
    "\n",
    "        source_dataset_path: Path = temp_dir / \"dataset\"\n",
    "\n",
    "        if source_dataset_path.exists():\n",
    "            shutil.move(source_dataset_path, dataset_path)\n",
    "            print(\"Dataset successfully downloaded.\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"Error: Could not find the 'dataset' folder inside the cloned repo at '{temp_dir}'.\"\n",
    "            )\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Git command failed: {e.stderr}\")\n",
    "\n",
    "    finally:\n",
    "        # Clean up\n",
    "        if temp_dir.exists():\n",
    "            shutil.rmtree(temp_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "b99c9929"
   },
   "outputs": [],
   "source": [
    "class OxfordPetDataset(Dataset):\n",
    "    def __init__(self, split: str, transform=None) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.root = dataset_path\n",
    "        self.split = split\n",
    "        self.names, self.labels = self._get_names_and_labels()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[Tensor, int]:\n",
    "        img_path = self.root / \"images\" / f\"{self.names[idx]}.jpg\"\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def get_num_classes(self) -> int:\n",
    "        return max(self.labels) + 1\n",
    "\n",
    "    def _get_names_and_labels(self) -> Tuple[List[str], List[int]]:\n",
    "        names = []\n",
    "        labels = []\n",
    "\n",
    "        with open(self.root / \"annotations\" / f\"{self.split}.txt\") as f:\n",
    "            for line in f:\n",
    "                name, label = line.replace(\"\\n\", \"\").split(\" \")\n",
    "                (names.append(name),)\n",
    "                labels.append(int(label) - 1)\n",
    "\n",
    "        return names, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XR1xyGG16n2l",
    "outputId": "6bc3b30b-fc4f-48d5-b7b1-ef6f0a04b9ab"
   },
   "outputs": [],
   "source": [
    "train_dataset1 = OxfordPetDataset(split=\"train\")\n",
    "print(len(train_dataset1))\n",
    "img, label = train_dataset1[0]\n",
    "print(img.size, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "ifMoNKZErJeP"
   },
   "outputs": [],
   "source": [
    "def breed_from_name(name):\n",
    "    return \"_\".join(name.split(\"_\")[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "emkFPsc9KCvX",
    "outputId": "9f6f371a-0dc4-4b1a-f607-a4a840c822c3"
   },
   "outputs": [],
   "source": [
    "# Images if we don't apply transformations\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(6):\n",
    "    img, _ = train_dataset1[i]\n",
    "    name = train_dataset1.names[i]\n",
    "\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(breed_from_name(name))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BstT-9u9KO-5",
    "outputId": "4e483ff0-6cb2-4a11-ea15-9815cd9db341"
   },
   "outputs": [],
   "source": [
    "# Images if we apply transformations\n",
    "train_transform = T.Compose(\n",
    "    [\n",
    "        T.Resize((256, 256)),\n",
    "        T.RandomCrop(224),\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transform = T.Compose(\n",
    "    [\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = OxfordPetDataset(split=\"train\", transform=train_transform)\n",
    "test_dataset = OxfordPetDataset(split=\"test\", transform=val_transform)\n",
    "validation_dataset = OxfordPetDataset(split=\"val\", transform=val_transform)\n",
    "print(\"Number of samples - train:\", len(train_dataset))\n",
    "print(\"Number of classes - train:\", train_dataset.get_num_classes())\n",
    "print(\"Number of samples - test:\", len(test_dataset))\n",
    "print(\"Number of classes - test:\", test_dataset.get_num_classes())\n",
    "print(\"Number of samples - validation:\", len(validation_dataset))\n",
    "print(\"Number of classes - validation:\", validation_dataset.get_num_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "N32ErS8zLLuz",
    "outputId": "7715abf1-3914-401a-a408-0cf1979ccbad"
   },
   "outputs": [],
   "source": [
    "logging.getLogger(\"matplotlib\").setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "def show_samples(dataset, n=6):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(n):\n",
    "        img, _ = dataset[i]\n",
    "        names = dataset.names[i]\n",
    "        # label = dataset.labels[i]\n",
    "        img = img.permute(1, 2, 0)\n",
    "\n",
    "        plt.subplot(2, n // 2, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"{breed_from_name(names)}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_samples(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "id": "WDJiLukJWBmO"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "val_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xz1YpyeRYSEZ",
    "outputId": "a8723cdc-9dc2-4b28-dd82-dfb4af163302"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape)\n",
    "print(images.min(), images.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image example after transformations\n",
    "def denormalized_img(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "    if tensor.ndim == 4:\n",
    "        mean = torch.tensor(mean, device=tensor.device).view(1, -1, 1, 1)\n",
    "        std = torch.tensor(std, device=tensor.device).view(1, -1, 1, 1)\n",
    "    else:\n",
    "        mean = torch.tensor(mean, device=tensor.device).view(-1, 1, 1)\n",
    "        std = torch.tensor(std, device=tensor.device).view(-1, 1, 1)\n",
    "    return tensor * std + mean\n",
    "\n",
    "index = torch.randperm(len(train_dataset))[:6]\n",
    "plt.figure(figsize=(15, 10))\n",
    "for ind, k in enumerate(index):\n",
    "  img, label = train_dataset[k]\n",
    "  img = denormalized_img(img).permute(1, 2, 0)\n",
    "  plt.subplot(2,3, ind+1)\n",
    "  plt.imshow(img)\n",
    "  plt.title(f\"Label: {label} - {breed_from_name(train_dataset.names[k])}\")\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "b4e655bd"
   },
   "source": [
    "## Part 1: design your own network\n",
    "\n",
    "Your goal is to implement a convolutional neural network for image classification and train it from scratch on `OxfordPetDataset`. You should consider yourselves satisfied once you obtain a classification accuracy on the test split of ~60%. You are free to achieve this however you want, except for a few rules you must follow:\n",
    "\n",
    "- Compile this notebook by displaying the results obtained by the best model you found throughout your experimentation; then show how, by removing some of its components, its performance drops. In other words, do an *ablation study* to prove that your design choices have a positive impact on the final result.\n",
    "\n",
    "- Do not instantiate an off-the-self PyTorch network. Instead, construct your network as a composition of existing PyTorch layers. In more concrete terms, you can use e.g. `torch.nn.Linear`, but you cannot use e.g. `torchvision.models.alexnet`.\n",
    "\n",
    "- Show your results and ablations with plots, tables, images, etc. â€” the clearer, the better.\n",
    "\n",
    "Don't be too concerned with your model performance: the ~60% is just to give you an idea of when to stop. Keep in mind that a thoroughly justified model with lower accuracy will be rewarded more points than a poorly experimentally validated model with higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "id": "ZOmvZnRXe8zd"
   },
   "source": [
    "## **NOTE:**\n",
    "- Several strategies and network architectures were explored, with the main objective of exploiting the components and architectures presented during the course. More advanced networks, such as EfficientNet, were also developed, achieving results very close to those of a simpler ResNet-inspired network. For this reason, the network that better leverages the course topics was ultimately chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "id": "pplftQBVy43G"
   },
   "source": [
    "## **Common Pipeline**\n",
    "\n",
    "**Includes:**\n",
    "- **Accuracy function:** takes into account different output structure when MixUp is employed or not\n",
    "- **Precision, Recall and F1 computation function**\n",
    "- **Evaluation function**\n",
    "- **Residual block class:** defines the structure of the residual blocks, taking into account the presence or not of the Batch Normalization layers\n",
    "- **Convolutional block class:** defines the structure of the convolutional blocks, which are employed when trying to evidence the impact of Residual blocks\n",
    "- **Network class:** defines the structure of the CNN, taking into account the use of Stem layers, Batch Normalization layers, Residual layers, Pooling layers and Dropout, to measure the impact of these components\n",
    "- **TrainConfig class:** defines some core parameters for the training process (like number of epochs, starting learning rate, MixUp parameter, label smoothing factor) and takes into account the use of Label Smoothing, Learning Rate Scheduler and MixUp data augmentation technique\n",
    "- **build_training_components function:** defines the structure of criterion, optimizer, scheduler and mixup according to boolean and values set in the TrainConfig class\n",
    "- **Train process function:** defines the pipeline for training the model, minimizing the loss function and updating weights, storing the model with the highest accuracy obtained in validation set\n",
    "- **Plot functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "id": "m1VDS3wNURdy"
   },
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    preds = outputs.argmax(dim=1)\n",
    "\n",
    "    # If labels are one-hot / soft (MixUp case)\n",
    "    if labels.ndim == 2:\n",
    "        labels = labels.argmax(dim=1)\n",
    "\n",
    "    return (preds == labels).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "id": "O_MbfrYVohUm"
   },
   "outputs": [],
   "source": [
    "def compute_precision_recall_f1(preds, labels, num_classes):\n",
    "    eps = 1e-8\n",
    "\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        tp = ((preds == cls) & (labels == cls)).sum().float()\n",
    "        fp = ((preds == cls) & (labels != cls)).sum().float()\n",
    "        fn = ((preds != cls) & (labels == cls)).sum().float()\n",
    "\n",
    "        precision = tp / (tp + fp + eps)\n",
    "        recall = tp / (tp + fn + eps)\n",
    "        f1 = 2 * precision * recall / (precision + recall + eps)\n",
    "\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    return (\n",
    "        torch.mean(torch.stack(precision_list)).item(),\n",
    "        torch.mean(torch.stack(recall_list)).item(),\n",
    "        torch.mean(torch.stack(f1_list)).item(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "id": "Ay6XhTZ1URdz"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            # Handle one-hot / soft labels\n",
    "            if labels.ndim == 2:\n",
    "                labels_hard = labels.argmax(dim=1)\n",
    "            else:\n",
    "                labels_hard = labels\n",
    "\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            total_correct += accuracy(outputs, labels)\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels_hard)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc = total_correct.float() / total_samples\n",
    "\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    precision, recall, f1 = compute_precision_recall_f1(\n",
    "        all_preds, all_labels, num_classes=outputs.size(1)\n",
    "    )\n",
    "\n",
    "    return avg_loss, avg_acc.item(), precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "id": "7xXNM7hMIzo1"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, use_batchnorm=True):\n",
    "        super().__init__()\n",
    "\n",
    "        norm = nn.BatchNorm2d if use_batchnorm else nn.Identity\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn1 = norm(out_channels)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = norm(out_channels)\n",
    "\n",
    "        # Skip connection adjustment if shape changes\n",
    "        self.skip = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels, out_channels, kernel_size=1, stride=stride, bias=False\n",
    "                ),\n",
    "                norm(out_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "        if self.skip is not None:\n",
    "            identity = self.skip(identity)\n",
    "\n",
    "        out += identity\n",
    "        return self.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "id": "ih1tQX4Xf-aJ"
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, use_batchnorm=True):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels) if use_batchnorm else nn.Identity(),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "id": "zsjgN192DYUA"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes,\n",
    "        use_stem=True,\n",
    "        use_residuals=True,\n",
    "        use_batchnorm=True,\n",
    "        use_pooling=True,\n",
    "        use_dropout=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_residuals = use_residuals\n",
    "\n",
    "        # Stem layers\n",
    "        if use_stem:\n",
    "            self.stem = nn.Sequential(\n",
    "                nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "        else:\n",
    "            # Minimal stem: only channel lifting, no downsampling or pooling\n",
    "            self.stem = nn.Sequential(\n",
    "                nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(64) if use_batchnorm else nn.Identity(),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "        # Residual blocks\n",
    "        self.stage1 = self._make_stage(\n",
    "            64, 64, num_blocks=2, stride=1, use_batchnorm=use_batchnorm\n",
    "        )\n",
    "        self.stage2 = self._make_stage(\n",
    "            64, 128, num_blocks=2, stride=2, use_batchnorm=use_batchnorm\n",
    "        )\n",
    "        self.stage3 = self._make_stage(\n",
    "            128, 256, num_blocks=2, stride=2, use_batchnorm=use_batchnorm\n",
    "        )\n",
    "        self.stage4 = self._make_stage(\n",
    "            256, 512, num_blocks=2, stride=2, use_batchnorm=use_batchnorm\n",
    "        )\n",
    "\n",
    "        # Classifier and Pooling\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1)) if use_pooling else None\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2) if use_dropout else nn.Identity(),\n",
    "            nn.Linear(256, n_classes),\n",
    "        )\n",
    "\n",
    "    def _make_stage(self, in_channels, out_channels, num_blocks, stride, use_batchnorm):\n",
    "        if not self.use_residuals:\n",
    "            # Plain conv blocks instead of residual blocks\n",
    "            layers = [ConvBlock(in_channels, out_channels, stride, use_batchnorm)]\n",
    "            for _ in range(1, num_blocks):\n",
    "                layers.append(ConvBlock(out_channels, out_channels, 1, use_batchnorm))\n",
    "            return nn.Sequential(*layers)\n",
    "        else:\n",
    "            layers = [ResidualBlock(in_channels, out_channels, stride, use_batchnorm)]\n",
    "            for _ in range(1, num_blocks):\n",
    "                layers.append(\n",
    "                    ResidualBlock(\n",
    "                        out_channels, out_channels, use_batchnorm=use_batchnorm\n",
    "                    )\n",
    "                )\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        if self.pool is not None:\n",
    "            x = self.pool(x)\n",
    "        else:\n",
    "            x = x.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "id": "DwIJFDnggkHm"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainConfig:\n",
    "    num_epochs: int = 100\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-2\n",
    "\n",
    "    use_scheduler: bool = False\n",
    "    use_label_smoothing: bool = False\n",
    "    label_smoothing: float = 0.1\n",
    "\n",
    "    use_mixup: bool = False\n",
    "    mixup_alpha: float = 0.2\n",
    "\n",
    "    save_path: str = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "id": "yxmzP0_JfKXp"
   },
   "outputs": [],
   "source": [
    "class NoMixUp:\n",
    "    def __call__(self, x, y):\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "id": "tEpb3xtwfUNa"
   },
   "outputs": [],
   "source": [
    "def build_training_components(model, train_loader, train_dataset, config: TrainConfig):\n",
    "    criterion = nn.CrossEntropyLoss(\n",
    "        label_smoothing=config.label_smoothing if config.use_label_smoothing else 0.0\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config.lr,\n",
    "        weight_decay=config.weight_decay,\n",
    "    )\n",
    "\n",
    "    scheduler = None\n",
    "    if config.use_scheduler:\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=config.lr,\n",
    "            epochs=config.num_epochs,\n",
    "            steps_per_epoch=len(train_loader),\n",
    "            pct_start=0.1,\n",
    "            anneal_strategy=\"cos\",\n",
    "        )\n",
    "\n",
    "    if config.use_mixup:\n",
    "        mixup = v2.MixUp(\n",
    "            alpha=config.mixup_alpha,\n",
    "            num_classes=train_dataset.get_num_classes(),\n",
    "        )\n",
    "    else:\n",
    "        mixup = NoMixUp()\n",
    "\n",
    "    return criterion, optimizer, scheduler, mixup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "`USE_MLFLOW` boolean object determines whether the training metrics, hyperparameters, model architectures, and artifacts across all PyTorch experiments along with system usage metrics [will be logged on the mlflow instance](https://mlflow.org/docs/latest/ml/deep-learning/pytorch/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_MLFLOW = True\n",
    "\n",
    "if USE_MLFLOW:\n",
    "    import mlflow\n",
    "    mlflow.set_tracking_uri(\"https://mlflow.niccolozanotti.com\")\n",
    "    mlflow.set_experiment(\"ipcv-pet-classification-exp\")\n",
    "    print(\"MLflow logging is ENABLED.\")\n",
    "else:\n",
    "    print(\"MLflow logging is DISABLED. Models will be saved locally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, model, train_loader, val_loader, criterion, optimizer, scheduler, mixup, device, config, use_mlflow=True):\n",
    "    \"\"\"\n",
    "    Training loop that conditionally logs to MLflow and returns history.\n",
    "    Assumes an MLflow run is ALREADY ACTIVE from the calling cell.\n",
    "    \"\"\"\n",
    "    # Initialize history\n",
    "    history = {\n",
    "        \"train_loss\": [], \"val_loss\": [],\n",
    "        \"train_acc\": [], \"val_acc\": [],\n",
    "        \"val_precision\": [], \"val_recall\": [], \"val_f1\": [],\n",
    "        \"lr\": []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(config.num_epochs):\n",
    "        model.train()\n",
    "        total_loss, total_correct, total_samples = 0.0, 0, 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Apply MixUp if configured\n",
    "            if config.use_mixup and mixup is not None:\n",
    "                images, labels = mixup(images, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            total_correct += accuracy(outputs, labels) \n",
    "            total_samples += images.size(0)\n",
    "\n",
    "        # Calculate Epoch Metrics\n",
    "        train_loss = total_loss / total_samples\n",
    "        train_acc = total_correct.float() / total_samples\n",
    "        \n",
    "        # Evaluate on Validation Set\n",
    "        val_loss, val_acc, val_precision, val_recall, val_f1 = evaluate(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "        \n",
    "        # --- Update History Dictionary ---\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"train_acc\"].append(train_acc.item())\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"val_precision\"].append(val_precision)\n",
    "        history[\"val_recall\"].append(val_recall)\n",
    "        history[\"val_f1\"].append(val_f1)\n",
    "        history[\"lr\"].append(current_lr)\n",
    "\n",
    "        if use_mlflow:\n",
    "            # Log metrics to MLflow per epoch\n",
    "            mlflow.log_metrics({\n",
    "                \"train_loss\": train_loss,\n",
    "                \"train_acc\": train_acc.item(),\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_acc\": val_acc,\n",
    "                \"val_precision\": val_precision,\n",
    "                \"val_recall\": val_recall,\n",
    "                \"val_f1\": val_f1,\n",
    "                \"lr\": current_lr\n",
    "            }, step=epoch)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{config.num_epochs}] | \"\n",
    "              f\"Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.3f} | \"\n",
    "              f\"Val Loss: {val_loss:.3f}, Val Acc: {val_acc:.3f} | LR: {current_lr:.2e}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            \n",
    "            # Standard local save\n",
    "            if config.save_path is not None:\n",
    "                torch.save(model.state_dict(), config.save_path)\n",
    "                \n",
    "            if use_mlflow:\n",
    "                # Uploads the PyTorch model artifact directly to MLflow\n",
    "                mlflow.pytorch.log_model(model, artifact_path=\"best_model\")\n",
    "\n",
    "    print(f\"[{model_name}] Finished! Best Validation Accuracy: {best_val_acc:.3f}\\n\")\n",
    "    return best_val_acc, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "id": "7fG4AXRd76yB"
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "    plt.figure()\n",
    "    plt.plot(history[\"train_acc\"])\n",
    "    plt.plot(history[\"val_acc\"])\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training vs Validation Accuracy\")\n",
    "    plt.legend([\"Train\", \"Validation\"])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.figure()\n",
    "    plt.plot(history[\"train_loss\"])\n",
    "    plt.plot(history[\"val_loss\"])\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training vs Validation Loss\")\n",
    "    plt.legend([\"Train\", \"Validation\"])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_learning_rate(history):\n",
    "    plt.figure()\n",
    "    plt.plot(history[\"lr\"])\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Learning Rate\")\n",
    "    plt.title(\"Learning Rate Schedule\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABLATION_CSV_PATH: Path = PROJECT_ROOT / \"ablation_test_results.csv\"\n",
    "ABLATION_JSON_PATH: Path = PROJECT_ROOT / \"ablation_histories.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previous CSV results if available\n",
    "if ABLATION_CSV_PATH.exists():\n",
    "    df_results = pd.read_csv(ABLATION_CSV_PATH)\n",
    "    results = df_results.to_dict(orient=\"records\")\n",
    "else:\n",
    "    results = []\n",
    "\n",
    "# Load previous histories if available\n",
    "if ABLATION_JSON_PATH.exists():\n",
    "    with open(ABLATION_JSON_PATH, \"r\") as f:\n",
    "        all_histories = json.load(f)\n",
    "else:\n",
    "    all_histories = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {
    "id": "LZZEX5bf-yo3"
   },
   "source": [
    "## **Model variant: Full model (baseline)**\n",
    "\n",
    "**Architecture**\n",
    "- Convolutional neural network implementing architectures and strategies faced during the course.\n",
    "- A convolutional stem composed of a three 3Ã—3 convolution (1st with stride=2 and others with stride=1), followed by Batch Normalization, ReLU activation, and max pooling.\n",
    "- Four sequential stages operating at increasing feature dimensions (64 â†’ 128 â†’ 256 â†’ 512).\n",
    "- Each stage consists of two residual blocks with identity skip connections.\n",
    "- When spatial resolution or channel dimensions change, skip connections are adapted using a 1Ã—1 convolution followed by Batch Normalization.\n",
    "- Global feature aggregation is performed using adaptive average pooling.\n",
    "- The classifier head consists of two fully connected layers with ReLU activation and dropout.\n",
    "\n",
    "**Normalization and regularization**\n",
    "- Batch Normalization is applied after every convolution, including within residual branches and skip connections.\n",
    "- Dropout is applied in the classifier to reduce overfitting.\n",
    "\n",
    "**Training setup**\n",
    "- Optimized using AdamW with weight decay.\n",
    "- Learning rate scheduling is enabled via OneCycleLR with cosine annealing.\n",
    "- Cross-entropy loss with label smoothing is used.\n",
    "- MixUp data augmentation is applied during training.\n",
    "- Gradient norm clipping is used to improve training stability.\n",
    "\n",
    "**Purpose**\n",
    "- This configuration serves as the baseline model against which all ablation studies are compared.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {
    "id": "6SYwWCuEIUSf"
   },
   "source": [
    "**NOTE:** All ablation variants modify a single component at a time while keeping the remaining architecture and training configuration identical to the baseline model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4dbgOCyJDBNH",
    "outputId": "f0802c86-10d9-4461-9c73-33f01a24ce50"
   },
   "outputs": [],
   "source": [
    "network_diagram = r\"\"\"\n",
    "digraph ImprovedNet {\n",
    "    rankdir=TB;\n",
    "    fontname=\"Helvetica\";\n",
    "    node [shape=record, fontname=\"Helvetica\"];\n",
    "\n",
    "    Input [\n",
    "        label=\"Input\\n3Ã—224Ã—224\"\n",
    "    ];\n",
    "\n",
    "    Stem [\n",
    "        label=\"{Stem|\n",
    "        Conv3Ã—3, s=2, p=1|\n",
    "        BN + ReLU|\n",
    "        Conv3Ã—3, s=1, p=1|\n",
    "        BN + ReLU|\n",
    "        Conv3Ã—3, s=1, p=1|\n",
    "        BN + ReLU|\n",
    "        Output: 64Ã—112Ã—112}\"\n",
    "    ];\n",
    "\n",
    "    Stage1 [\n",
    "        label=\"{Stage 1:\n",
    "        2Ã—ResidualBlock|\n",
    "        RB1:\n",
    "        Conv3Ã—3 â†’ BN â†’ ReLU +\n",
    "        Conv3Ã—3 â†’ BN\n",
    "        + Identity|\n",
    "        RB2:\n",
    "        Conv3Ã—3 â†’ BN â†’ ReLU +\n",
    "        Conv3Ã—3 â†’ BN\n",
    "        + Identity|\n",
    "        Output: 64x56x56}\"\n",
    "    ];\n",
    "\n",
    "    Stage2 [\n",
    "        label=\"{Stage 2:\n",
    "        2Ã—ResidualBlock|\n",
    "        RB1:\n",
    "        Conv3Ã—3, s=2 + BN + ReLU +\n",
    "        Conv3Ã—3 + BN\n",
    "        + Skip Conv1Ã—1, s=2 + BN|\n",
    "        Output: 128x28x28|\n",
    "        RB2:\n",
    "        Conv3Ã—3 + BN + ReLU +\n",
    "        Conv3Ã—3 + BN|\n",
    "        Output: 128x28x28}\"\n",
    "    ];\n",
    "\n",
    "    Stage3 [\n",
    "        label=\"{Stage 3:\n",
    "        2Ã—ResidualBlock|\n",
    "        RB1:\n",
    "        Conv3Ã—3, s=2 + BN + ReLU +\n",
    "        Conv3Ã—3 + BN\n",
    "        + Skip Conv1Ã—1, s=2 + BN|\n",
    "        Output: 256x14x14|\n",
    "        RB2:\n",
    "        Conv3Ã—3 + BN + ReLU +\n",
    "        Conv3Ã—3 + BN|\n",
    "        Output: 256x14x14}\"\n",
    "    ];\n",
    "\n",
    "    Stage4 [\n",
    "        label=\"{Stage 4:\n",
    "        2Ã—ResidualBlock|\n",
    "        RB1:\n",
    "        Conv3Ã—3, s=2 + BN + ReLU +\n",
    "        Conv3Ã—3 + BN\n",
    "        + Skip Conv1Ã—1, s=2 + BN|\n",
    "        Output: 512x7x7|\n",
    "        RB2:\n",
    "        Conv3Ã—3 + BN + ReLU +\n",
    "        Conv3Ã—3 + BN|\n",
    "        Output: 512x7x7}\"\n",
    "    ];\n",
    "\n",
    "    Pool [\n",
    "        label=\"AdaptiveAvgPool\\n512Ã—1Ã—1\"\n",
    "    ];\n",
    "\n",
    "    FC [\n",
    "        label=\"{Classifier|\n",
    "        Linear 512â†’256 + ReLU|\n",
    "        Dropout p=0.2|\n",
    "        Linear 256â†’N classes}\"\n",
    "    ];\n",
    "\n",
    "    Output [\n",
    "        label=\"Output\\nN classes\"\n",
    "    ];\n",
    "\n",
    "    Input -> Stem -> Stage1 -> Stage2 -> Stage3 -> Stage4 -> Pool -> FC -> Output;\n",
    "}\n",
    "\"\"\"\n",
    "draw_diagram(network_diagram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "We now choose the right GPU-acceleration backend to speed up our model(s) training. The following code chunk allows for CUDA (NVIDIA chips backend) or MPS (Apple Silicon chips backend) devices with fallback to CPU. \n",
    "The outputs in this notebook were obtained by running it for $\\sim 5$ hours on a [NVIDIA L40 GPU](https://www.nvidia.com/en-us/data-center/l40/). You can find the used sbatch script [here](https://github.com/niccolozanotti/ipcv-assignments/blob/main/scripts/run-task2.sbatch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "match (torch.cuda.is_available(), torch.backends.mps.is_available()):\n",
    "    case (True, _):\n",
    "        device = torch.device(\"cuda\")\n",
    "    case (False, True):\n",
    "        device = torch.device(\"mps\")\n",
    "    case _:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ablation_experiment(\n",
    "    model_name, \n",
    "    model_kwargs=None, \n",
    "    config_kwargs=None, \n",
    "    custom_train_dataset=None, \n",
    "    custom_train_loader=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs a single ablation experiment, handles all MLflow logging, \n",
    "    local saving, and plotting.\n",
    "    \"\"\"\n",
    "    model_kwargs = model_kwargs or {}\n",
    "    config_kwargs = config_kwargs or {}\n",
    "    \n",
    "    # Use defaults unless custom ones are provided (for Model 6)\n",
    "    ds_train = custom_train_dataset if custom_train_dataset else train_dataset\n",
    "    dl_train = custom_train_loader if custom_train_loader else train_loader\n",
    "\n",
    "    # 1. Open the MLflow Run\n",
    "    run_context = mlflow.start_run(run_name=model_name) if USE_MLFLOW else nullcontext()\n",
    "    \n",
    "    with run_context:\n",
    "        \n",
    "        # Initialize model with dynamic arguments\n",
    "        model = Net(n_classes=ds_train.get_num_classes(), **model_kwargs).to(device)\n",
    "\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"=== Running: {model_name} ===\")\n",
    "        print(f\"Total parameters: {total_params:,} | Trainable: {trainable_params:,}\")\n",
    "        \n",
    "        if USE_MLFLOW:\n",
    "            mlflow.log_param(\"total_params\", total_params)\n",
    "\n",
    "        # Setup Config with dynamic overrides\n",
    "        default_config = {\n",
    "            \"use_scheduler\": True,\n",
    "            \"use_label_smoothing\": True,\n",
    "            \"use_mixup\": True,\n",
    "            \"save_path\": f\"best_{model_name.replace(' ', '_')}.pth\"\n",
    "        }\n",
    "        default_config.update(config_kwargs) # Overwrite defaults with any passed kwargs\n",
    "        config = TrainConfig(**default_config)\n",
    "        \n",
    "        if USE_MLFLOW:\n",
    "            mlflow.log_params(vars(config))\n",
    "\n",
    "        # Build training components\n",
    "        criterion, optimizer, scheduler, mixup = build_training_components(\n",
    "            model=model,\n",
    "            train_loader=dl_train,\n",
    "            train_dataset=ds_train,\n",
    "            config=config,\n",
    "        )\n",
    "\n",
    "        # 2. Train the model\n",
    "        best_acc, history = train_model(\n",
    "            model_name=model_name,\n",
    "            model=model,\n",
    "            train_loader=dl_train,\n",
    "            val_loader=val_loader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            mixup=mixup,\n",
    "            device=device,\n",
    "            config=config,\n",
    "            use_mlflow=USE_MLFLOW,\n",
    "        )\n",
    "\n",
    "        # 3. Load best weights and Evaluate\n",
    "        model.load_state_dict(torch.load(config.save_path, map_location=device))\n",
    "        model.to(device)\n",
    "\n",
    "        test_loss, test_acc, test_prec, test_recall, test_f1 = evaluate(\n",
    "            model, test_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        print(f\"[{model_name}] Test Loss: {test_loss:.3f} | Test Acc: {test_acc:.3f}\")\n",
    "\n",
    "        # 4. Log to MLflow\n",
    "        if USE_MLFLOW:\n",
    "            mlflow.log_metrics({\n",
    "                \"test_loss\": test_loss, \"test_accuracy\": test_acc,\n",
    "                \"test_precision\": test_prec, \"test_recall\": test_recall, \"test_f1\": test_f1,\n",
    "            })\n",
    "            mlflow.pytorch.log_model(model, artifact_path=\"model\")\n",
    "\n",
    "    # --- Local Saving and Plotting ---\n",
    "    \n",
    "    # Update global results list (removes previous run of the same model if it exists)\n",
    "    global results, all_histories \n",
    "    results = [r for r in results if r[\"Model\"] != model_name]\n",
    "    results.append({\n",
    "        \"Model\": model_name, \"Test Loss\": test_loss, \"Test Accuracy\": test_acc,\n",
    "        \"Test Precision\": test_prec, \"Test Recall\": test_recall, \"Test F1\": test_f1,\n",
    "    })\n",
    "    \n",
    "    all_histories[model_name] = history\n",
    "\n",
    "    # Save to disk\n",
    "    pd.DataFrame(results).round(4).to_csv(ABLATION_CSV_PATH, index=False)\n",
    "    with open(ABLATION_JSON_PATH, \"w\") as f:\n",
    "        json.dump(all_histories, f, indent=4)\n",
    "\n",
    "    # Plot\n",
    "    plot_accuracy(history)\n",
    "    plot_loss(history)\n",
    "    plot_learning_rate(history)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1\n",
    "run_ablation_experiment(\"Baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {
    "id": "i4Um0-dky8PE"
   },
   "source": [
    "## **Model variant: No Batch Normalization**\n",
    "\n",
    "**Change**\n",
    "- Removed all Batch Normalization layers from the network, including those in residual skip connections.\n",
    "\n",
    "**Purpose**\n",
    "- To assess the contribution of Batch Normalization to training stability and final performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2\n",
    "run_ablation_experiment(\"No BatchNorm\", model_kwargs={\"use_batchnorm\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "## **Model variant: No Pooling**\n",
    "\n",
    "**Change**\n",
    "- Removed all pooling operations from the network, including max pooling in the stem and global average pooling before the classifier.\n",
    "\n",
    "**Purpose**\n",
    "- To evaluate the role of spatial downsampling and global feature aggregation in representation learning and classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3\n",
    "run_ablation_experiment(\"No Pooling\", model_kwargs={\"use_pooling\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {
    "id": "AXFXA796Dl8a"
   },
   "source": [
    "## **Model variant: No Dropout**\n",
    "\n",
    "**Change**\n",
    "- Removed dropout from the classifier head while keeping the rest of the architecture unchanged.\n",
    "\n",
    "**Purpose**\n",
    "- To assess the impact of dropout-based regularization on overfitting and generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4\n",
    "run_ablation_experiment(\"No Dropout\", model_kwargs={\"use_dropout\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {
    "id": "Z3_-LcAoy-lC"
   },
   "source": [
    "## **Model variant: No MixUp**\n",
    "\n",
    "**Change**\n",
    "- Disabled MixUp data augmentation during training, using only standard inputâ€“label pairs.\n",
    "\n",
    "**Purpose**\n",
    "- To measure the effect of MixUp on model robustness and generalization compared to standard supervised training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5\n",
    "run_ablation_experiment(\"No MixUp\", config_kwargs={\"use_mixup\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {
    "id": "yxBAwp_9zBUU"
   },
   "source": [
    "## **Model variant: No Data Augmentation**\n",
    "\n",
    "**Change**\n",
    "- Disabled all data augmentation techniques during training, including MixUp and any other stochastic input transformations.\n",
    "\n",
    "**Purpose**\n",
    "- To isolate the contribution of data augmentation to model generalization and performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 6 (Requires custom dataset/loader logic first)\n",
    "train_transform2 = T.Compose([\n",
    "    T.Resize((224, 224)), T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "train_dataset2 = OxfordPetDataset(split=\"train\", transform=train_transform2)\n",
    "train_loader2 = DataLoader(train_dataset2, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "run_ablation_experiment(\n",
    "    \"No Augmentation\", \n",
    "    config_kwargs={\"use_mixup\": False},\n",
    "    custom_train_dataset=train_dataset2,\n",
    "    custom_train_loader=train_loader2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {
    "id": "95a7DbvjzDwC"
   },
   "source": [
    "## **Model variant: No Stem Layer**\n",
    "\n",
    "**Change**\n",
    "- Removed the convolutional stem (7Ã—7 convolution, Batch Normalization, ReLU, and max pooling), feeding inputs directly into the first stage of the network.\n",
    "\n",
    "**Purpose**\n",
    "- To investigate the importance of early-stage feature extraction and aggressive spatial downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3C8qpU3iJHaf",
    "outputId": "daa3368a-6864-4bf4-b67d-81b20bd5f432"
   },
   "outputs": [],
   "source": [
    "# Model 7\n",
    "run_ablation_experiment(\"No StemLayer\", model_kwargs={\"use_stem\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {
    "id": "iUnS-uhgzGRZ"
   },
   "source": [
    "## **Model variant: No Residual Blocks**\n",
    "\n",
    "**Change**\n",
    "- Replaced all residual blocks with plain convolutional blocks, removing skip connections while preserving depth and channel dimensions.\n",
    "\n",
    "**Purpose**\n",
    "- To evaluate the contribution of residual connections to optimization stability and final accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 8\n",
    "run_ablation_experiment(\"No Residual\", model_kwargs={\"use_residuals\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {
    "id": "lk6V2lsqzaXD"
   },
   "source": [
    "## **Model variant: No Label Smoothing**\n",
    "\n",
    "**Change**\n",
    "- Disabled label smoothing in the cross-entropy loss, using hard one-hot target labels during training.\n",
    "\n",
    "**Purpose**\n",
    "- To assess the effect of label smoothing on model calibration and generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 9\n",
    "run_ablation_experiment(\"No LabelSmoothing\", config_kwargs={\"use_label_smoothing\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {
    "id": "CJA79QmBzcam"
   },
   "source": [
    "## **Model variant: No Learning Rate Scheduler**\n",
    "\n",
    "**Change**\n",
    "- Disabled the learning rate scheduler, training the model with a constant learning rate throughout all epochs.\n",
    "\n",
    "**Purpose**\n",
    "- To evaluate the impact of dynamic learning rate scheduling on convergence speed and final performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 10\n",
    "run_ablation_experiment(\"No LR Scheduler\", config_kwargs={\"use_scheduler\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {
    "id": "CZ_KSPucY2PD"
   },
   "source": [
    "## **RECAP**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_order = [\n",
    "    \"Baseline\",\n",
    "    \"No BatchNorm\",\n",
    "    \"No Pooling\",\n",
    "    \"No Dropout\",\n",
    "    \"No MixUp\",\n",
    "    \"No Augmentation\",\n",
    "    \"No StemLayer\",\n",
    "    \"No Residual\",\n",
    "    \"No LabelSmoothing\",\n",
    "    \"No LR Scheduler\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "for model in model_order:\n",
    "    if model in all_histories:\n",
    "        plt.plot(all_histories[model][\"val_acc\"])\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Validation Accuracy - Ablation Study\")\n",
    "plt.legend(\n",
    "    [m for m in model_order if m in all_histories],\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    ")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "for model in model_order:\n",
    "    if model in all_histories:\n",
    "        plt.plot(all_histories[model][\"train_loss\"])\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss - Ablation Study\")\n",
    "plt.legend(\n",
    "    [m for m in model_order if m in all_histories],\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    ")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {
    "id": "192fb2ce"
   },
   "source": [
    "## Part 2: fine-tune an existing network\n",
    "\n",
    "Your goal is to fine-tune a pretrained ResNet-18 model on `OxfordPetDataset`. Use the implementation provided by PyTorch, i.e. the opposite of part 1. Specifically, use the PyTorch ResNet-18 model pretrained on ImageNet-1K (V1). Divide your fine-tuning into two parts:\n",
    "\n",
    "2A. First, fine-tune the ResNet-18 with the same training hyperparameters you used for your best model in part 1.\n",
    "\n",
    "2B. Then, tweak the training hyperparameters in order to increase the accuracy on the test split. Justify your choices by analyzing the training plots and/or citing sources that guided you in your decisions â€” papers, blog posts, YouTube videos, or whatever else you may find useful. You should consider yourselves satisfied once you obtain a classification accuracy on the test split of ~90%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "Approach with helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_finetuning_stage(\n",
    "    model_name,\n",
    "    model,\n",
    "    config,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    mixup_fn,\n",
    "    custom_mlflow_params=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Executes a fine-tuning stage, handling training, evaluation, \n",
    "    MLflow logging, local saving, and plotting.\n",
    "    \"\"\"\n",
    "    # 1. Open MLflow context\n",
    "    run_context = mlflow.start_run(run_name=model_name) if USE_MLFLOW else nullcontext()\n",
    "    \n",
    "    with run_context:\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*50)\n",
    "        print(f\"=== Running: {model_name} ===\")\n",
    "        print(f\"Total params: {total_params:,} | Trainable params: {trainable_params:,}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        if USE_MLFLOW:\n",
    "            mlflow.log_param(\"total_params\", total_params)\n",
    "            mlflow.log_param(\"trainable_params\", trainable_params)\n",
    "            mlflow.log_params(vars(config))\n",
    "            if custom_mlflow_params:\n",
    "                mlflow.log_params(custom_mlflow_params)\n",
    "\n",
    "        # 2. Train the model\n",
    "        best_acc, history = train_model(\n",
    "            model_name=model_name,\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            mixup=mixup_fn,\n",
    "            device=device,\n",
    "            config=config,\n",
    "            use_mlflow=USE_MLFLOW,\n",
    "        )\n",
    "\n",
    "        # 3. Load best weights and Evaluate\n",
    "        model.load_state_dict(torch.load(config.save_path, map_location=device))\n",
    "        model.to(device)\n",
    "\n",
    "        test_loss, test_acc, test_prec, test_recall, test_f1 = evaluate(\n",
    "            model, test_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        print(f\"[{model_name}] Test Loss: {test_loss:.3f} | Test Acc: {test_acc:.3f}\")\n",
    "\n",
    "        # 4. Log to MLflow\n",
    "        if USE_MLFLOW:\n",
    "            mlflow.log_metrics({\n",
    "                \"test_loss\": test_loss, \"test_accuracy\": test_acc,\n",
    "                \"test_precision\": test_prec, \"test_recall\": test_recall, \"test_f1\": test_f1,\n",
    "            })\n",
    "            mlflow.pytorch.log_model(model, artifact_path=\"model\")\n",
    "\n",
    "    # --- Local Saving and Plotting ---\n",
    "    global results, all_histories \n",
    "    results = [r for r in results if r[\"Model\"] != model_name]\n",
    "    results.append({\n",
    "        \"Model\": model_name, \"Test Loss\": test_loss, \"Test Accuracy\": test_acc,\n",
    "        \"Test Precision\": test_prec, \"Test Recall\": test_recall, \"Test F1\": test_f1,\n",
    "    })\n",
    "    all_histories[model_name] = history\n",
    "\n",
    "    pd.DataFrame(results).round(4).to_csv(ABLATION_CSV_PATH, index=False)\n",
    "    with open(ABLATION_JSON_PATH, \"w\") as f:\n",
    "        json.dump(all_histories, f, indent=4)\n",
    "\n",
    "    plot_accuracy(history)\n",
    "    plot_loss(history)\n",
    "    plot_learning_rate(history)\n",
    "    \n",
    "    return test_acc # Returning this so we can compare 2A and 2B later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Part 2A: Fine-tune ResNet-18 (Same hyperparameters as Part 1)\n",
    "# ==============================================================================\n",
    "\n",
    "# Setup Model\n",
    "resnet18_2a = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "resnet18_2a.fc = nn.Linear(resnet18_2a.fc.in_features, train_dataset.get_num_classes())\n",
    "resnet18_2a = resnet18_2a.to(device)\n",
    "\n",
    "# Setup Components\n",
    "config_2a = TrainConfig(use_scheduler=True, use_label_smoothing=True, use_mixup=True, save_path=\"best_resnet18_2a.pth\")\n",
    "crit_2a, opt_2a, sched_2a, mix_2a = build_training_components(resnet18_2a, train_loader, train_dataset, config_2a)\n",
    "\n",
    "# Run\n",
    "test_acc_2a = run_finetuning_stage(\"ResNet-18 Fine-tuned (Part 2A)\", resnet18_2a, config_2a, crit_2a, opt_2a, sched_2a, mix_2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {
    "id": "fcf86e41"
   },
   "source": [
    "## Part 2B: Fine-tune ResNet-18 with optimized hyperparameters\n",
    "\n",
    "**Changes from Part 2A:**\n",
    "A two stage fine-tuning strategy was used, first training only the classifier head and then fine-tuning the full network. This two stage approach involves:\n",
    "\n",
    "- **Different classifier layer**: in the classifier, dropout was applied with a $p=0.4$ \n",
    "- **Different learning rate behaviour and scheduler**: Cosine LR scheduler was applied, with a smaller lr while unfreezing the backbone ($lr=1e-3$ when fine tuning only the head, $lr=1e-5$ when fine tuning all layers)\n",
    "- **Smaller Label Smoothing**: Label smoothing of 0.05 was used\n",
    "- **Freeze backbone initially**: Train only the classifier first, then unfreeze the backbone and retrain the whole network\n",
    "\n",
    "**Justification:**\n",
    " - Using a two stage fine-tuning strategy follows standard transfer learning practice: pretrained CNN backbones learn general visual features that transfer across tasks, making head-only training effective for initial adaptation (*\"How transferable are features in deep neural networks?\", Yosinski et al., 2014*; PyTorch Transfer Learning Tutorial).\n",
    " - After initial convergence, unfreezing the entire network with a lower learning rate allows task-specific refinement while preserving useful pretrained representations (*\"Hands-on Transfer Learning with Python: Implement advanced deep learning and neural network models using TensorFlow and Keras\", Sarkar, Bali, 2018*).\n",
    " - Techniques such as weight decay, cosine LR scheduling and label smoothing shown to improve generalization in modern CNNs (*\"Bag of Tricks for Image Classification with Convolutional Neural Networks\", He et al., 2020*).\n",
    " - The pretrained features are already well-optimized for image classification; aggressive updates can degrade them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5d80bdd",
    "outputId": "20027e75-bc05-47c0-b43c-6fa101c9fef4"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Part 2B - Stage 1: Fine-tune only the head (Optimized HPs)\n",
    "# ==============================================================================\n",
    "\n",
    "# Setup Model\n",
    "resnet18_2b = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "resnet18_2b.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.4, inplace=False),\n",
    "    nn.Linear(in_features=512, out_features=train_dataset.get_num_classes(), bias=True),\n",
    ")\n",
    "resnet18_2b = resnet18_2b.to(device)\n",
    "\n",
    "# Freeze base, unfreeze head\n",
    "resnet18_2b.requires_grad_(False)\n",
    "resnet18_2b.fc.requires_grad_(True)\n",
    "\n",
    "# Setup Components\n",
    "config_2b_head = TrainConfig(use_scheduler=True, use_label_smoothing=True, use_mixup=False, save_path=\"best_resnet18_2b_head.pth\")\n",
    "config_2b_head.num_epochs = 100\n",
    "\n",
    "crit_2b = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "opt_fc = torch.optim.AdamW(resnet18_2b.fc.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "sched_fc = torch.optim.lr_scheduler.CosineAnnealingLR(opt_fc, T_max=100)\n",
    "\n",
    "# Run\n",
    "run_finetuning_stage(\n",
    "    \"ResNet-18 FT Head (Part 2B)\", resnet18_2b, config_2b_head, crit_2b, opt_fc, sched_fc, NoMixUp(), \n",
    "    custom_mlflow_params={\"stage\": \"head_only\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Part 2B - Stage 2: Fine-tune all layers (Optimized HPs)\n",
    "# ==============================================================================\n",
    "\n",
    "# Unfreeze all layers\n",
    "resnet18_2b.requires_grad_(True)\n",
    "\n",
    "# Setup Components\n",
    "config_2b_full = TrainConfig(use_scheduler=True, use_label_smoothing=True, use_mixup=False, save_path=\"best_resnet18_2b_full.pth\")\n",
    "config_2b_full.num_epochs = 100\n",
    "\n",
    "opt_full = torch.optim.AdamW(resnet18_2b.parameters(), lr=1e-5, weight_decay=1e-3)\n",
    "sched_full = torch.optim.lr_scheduler.CosineAnnealingLR(opt_full, T_max=100)\n",
    "\n",
    "# Run\n",
    "test_acc_2b2 = run_finetuning_stage(\n",
    "    \"ResNet-18 FT Full (Part 2B)\", resnet18_2b, config_2b_full, crit_2b, opt_full, sched_full, NoMixUp(),\n",
    "    custom_mlflow_params={\"stage\": \"full_network\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Summary comparison: Part 2A vs Part 2B\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Part 2 Summary: ResNet-18 Fine-tuning Results\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Part 2A (same hyperparameters as Part 1):\")\n",
    "print(f\"  Test Accuracy: {test_acc_2a:.3f}\")\n",
    "print(f\"\\nPart 2B (optimized hyperparameters for transfer learning):\")\n",
    "print(f\"  Test Accuracy: {test_acc_2b2:.3f}\")\n",
    "print(f\"\\nImprovement: {(test_acc_2b2 - test_acc_2a) * 100:.2f} percentage points\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
